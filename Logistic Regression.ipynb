{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_und = pd.read_csv(\"cleaned_rain_x.csv\")\n",
    "y_und = pd.read_csv(\"cleaned_rain_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Split into testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_und, y_und, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create 'Total' Train DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22845</th>\n",
       "      <td>-0.925855</td>\n",
       "      <td>-1.343428</td>\n",
       "      <td>0.213256</td>\n",
       "      <td>0.145445</td>\n",
       "      <td>1.220578</td>\n",
       "      <td>0.274457</td>\n",
       "      <td>0.183993</td>\n",
       "      <td>0.755625</td>\n",
       "      <td>1.500069</td>\n",
       "      <td>0.894962</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088941</td>\n",
       "      <td>-0.929551</td>\n",
       "      <td>-0.843587</td>\n",
       "      <td>-0.839679</td>\n",
       "      <td>1.169532</td>\n",
       "      <td>-0.846416</td>\n",
       "      <td>-0.822150</td>\n",
       "      <td>1.097495</td>\n",
       "      <td>1.094764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42446</th>\n",
       "      <td>1.314874</td>\n",
       "      <td>0.856220</td>\n",
       "      <td>0.352357</td>\n",
       "      <td>0.376646</td>\n",
       "      <td>0.437868</td>\n",
       "      <td>0.382385</td>\n",
       "      <td>1.842494</td>\n",
       "      <td>-0.917119</td>\n",
       "      <td>-0.666636</td>\n",
       "      <td>0.499156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088941</td>\n",
       "      <td>1.075788</td>\n",
       "      <td>1.185414</td>\n",
       "      <td>-0.839679</td>\n",
       "      <td>-0.855043</td>\n",
       "      <td>-0.846416</td>\n",
       "      <td>-0.822150</td>\n",
       "      <td>-0.911166</td>\n",
       "      <td>1.094764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>0.610645</td>\n",
       "      <td>0.741206</td>\n",
       "      <td>-0.273598</td>\n",
       "      <td>0.376646</td>\n",
       "      <td>0.214237</td>\n",
       "      <td>0.166529</td>\n",
       "      <td>0.137924</td>\n",
       "      <td>-0.533211</td>\n",
       "      <td>-0.666636</td>\n",
       "      <td>0.894962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918324</td>\n",
       "      <td>-0.929551</td>\n",
       "      <td>-0.843587</td>\n",
       "      <td>1.190932</td>\n",
       "      <td>1.169532</td>\n",
       "      <td>-0.846416</td>\n",
       "      <td>1.216322</td>\n",
       "      <td>1.097495</td>\n",
       "      <td>-0.913439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39347</th>\n",
       "      <td>-0.077579</td>\n",
       "      <td>0.223641</td>\n",
       "      <td>0.491458</td>\n",
       "      <td>-1.126157</td>\n",
       "      <td>-1.462998</td>\n",
       "      <td>0.382385</td>\n",
       "      <td>-0.645257</td>\n",
       "      <td>-0.231568</td>\n",
       "      <td>-0.666636</td>\n",
       "      <td>0.499156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918324</td>\n",
       "      <td>-0.929551</td>\n",
       "      <td>-0.843587</td>\n",
       "      <td>1.190932</td>\n",
       "      <td>1.169532</td>\n",
       "      <td>-0.846416</td>\n",
       "      <td>1.216322</td>\n",
       "      <td>1.097495</td>\n",
       "      <td>-0.913439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>-1.117918</td>\n",
       "      <td>-0.811487</td>\n",
       "      <td>-0.690902</td>\n",
       "      <td>-0.779357</td>\n",
       "      <td>0.214237</td>\n",
       "      <td>1.299772</td>\n",
       "      <td>-0.092423</td>\n",
       "      <td>1.797663</td>\n",
       "      <td>1.500069</td>\n",
       "      <td>-1.479872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918324</td>\n",
       "      <td>1.075788</td>\n",
       "      <td>-0.843587</td>\n",
       "      <td>-0.839679</td>\n",
       "      <td>1.169532</td>\n",
       "      <td>-0.846416</td>\n",
       "      <td>1.216322</td>\n",
       "      <td>1.097495</td>\n",
       "      <td>-0.913439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "22845 -0.925855 -1.343428  0.213256  0.145445  1.220578  0.274457  0.183993   \n",
       "42446  1.314874  0.856220  0.352357  0.376646  0.437868  0.382385  1.842494   \n",
       "5989   0.610645  0.741206 -0.273598  0.376646  0.214237  0.166529  0.137924   \n",
       "39347 -0.077579  0.223641  0.491458 -1.126157 -1.462998  0.382385 -0.645257   \n",
       "31998 -1.117918 -0.811487 -0.690902 -0.779357  0.214237  1.299772 -0.092423   \n",
       "\n",
       "              7         8         9  ...        15        16        17  \\\n",
       "22845  0.755625  1.500069  0.894962  ...  1.088941 -0.929551 -0.843587   \n",
       "42446 -0.917119 -0.666636  0.499156  ...  1.088941  1.075788  1.185414   \n",
       "5989  -0.533211 -0.666636  0.894962  ... -0.918324 -0.929551 -0.843587   \n",
       "39347 -0.231568 -0.666636  0.499156  ... -0.918324 -0.929551 -0.843587   \n",
       "31998  1.797663  1.500069 -1.479872  ... -0.918324  1.075788 -0.843587   \n",
       "\n",
       "             18        19        20        21        22        23  \\\n",
       "22845 -0.839679  1.169532 -0.846416 -0.822150  1.097495  1.094764   \n",
       "42446 -0.839679 -0.855043 -0.846416 -0.822150 -0.911166  1.094764   \n",
       "5989   1.190932  1.169532 -0.846416  1.216322  1.097495 -0.913439   \n",
       "39347  1.190932  1.169532 -0.846416  1.216322  1.097495 -0.913439   \n",
       "31998 -0.839679  1.169532 -0.846416  1.216322  1.097495 -0.913439   \n",
       "\n",
       "       RainTomorrow  \n",
       "22845             0  \n",
       "42446             1  \n",
       "5989              0  \n",
       "39347             1  \n",
       "31998             1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_total = pd.concat([x_train, y_train], axis=1)\n",
    "x_train_total.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "x_train_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluators\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(y_actu, y_pred):\n",
    "    TP = np.sum(np.logical_and(y_pred == 1, y_actu == 1))\n",
    "    TN = np.sum(np.logical_and(y_pred == 0, y_actu == 0))\n",
    "    FP = np.sum(np.logical_and(y_pred == 1, y_actu == 0))\n",
    "    FN = np.sum(np.logical_and(y_pred == 0, y_actu == 1))\n",
    "    print(TP, FP, TN, FN)\n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(models, test_x, test_y):\n",
    "    for m in models:\n",
    "        model = m[0]\n",
    "        TP, FP, TN, FN = TF(test_y, np.array(model.predict(test_x)))\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        pre = TP / (TP + FP)\n",
    "        re = TP / (FN + TP)\n",
    "        f1 = (2 * (pre * re)) / (pre + re)\n",
    "        scoring = {m[1]:{\"Accuracy\":acc, \"Precision\":pre,\"Recall\":re,\"F1\":f1}}\n",
    "    return pd.DataFrame(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Gradient Descent Logistic Regression Implementation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDLogReg:\n",
    "\n",
    "      #### Helper Functions ##########\n",
    "\n",
    "    def add_const(self, dataframe):\n",
    "        n, k = dataframe.shape\n",
    "        ones = np.ones((n, 1))\n",
    "        return np.concatenate([ones, dataframe], axis = 1)\n",
    "\n",
    "    def sigmoid(self, t):\n",
    "        return 1/(1 + np.exp(-t))\n",
    "\n",
    "    def ce(self, pred, y):\n",
    "        y = y.to_numpy()\n",
    "        total = 0\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] == 0:\n",
    "                x = 0.0000001\n",
    "            else:\n",
    "                x = pred[i]\n",
    "            total += y[i] * log(x)\n",
    "        return -total\n",
    "\n",
    "      ################################\n",
    "\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "        self.fit()\n",
    "\n",
    "    def fit(self, X=x_train, y=y_train[\"RainTomorrow\"], l_rate=.01, epochs=101):\n",
    "        X = self.add_const(X)\n",
    "\n",
    "        n, d = X.shape\n",
    "\n",
    "        # 1. initialize theta at random\n",
    "        self.theta = np.zeros((d, ))\n",
    "\n",
    "        # 2. repeat until stopping conditions\n",
    "        for epoch in range(epochs):\n",
    "          \n",
    "            theta_old = self.theta\n",
    "          \n",
    "            prediction = self.sigmoid(X @ theta_old)\n",
    "          \n",
    "            gradient = np.matmul(X.T, (prediction-y)) / n\n",
    "          \n",
    "            # 3. update theta\n",
    "            self.theta -= l_rate * gradient\n",
    "\n",
    "            cross_entropy = self.ce(prediction, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X=x_test):\n",
    "        if self.theta is None:\n",
    "            raise RuntimeError('Model has not been fit yet')\n",
    "        X = self.add_const(X)\n",
    "        return np.rint(self.sigmoid(X @ self.theta)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# RESULTS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-85b5b8bb8adf>:11: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6427 6326 0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.503960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.670177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.503960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression\n",
       "Accuracy              0.503960\n",
       "F1                    0.670177\n",
       "Precision             0.503960\n",
       "Recall                1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = GDLogReg()\n",
    "eval([[LR, \"Logistic Regression\"]], x_test, y_test['RainTomorrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
